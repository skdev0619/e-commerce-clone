# 카프카 

## 1. 카프카 서버
### 브로커 (Broker)
> `하나의 카프카 서버를 브로커(Broker)` 라고 한다. 
- 브로커는 프로듀서로부터 메시지를 수신하고 오프셋을 지정한 후 해당 메시지를 디스크에 저장한다. 
- 컨슈머의 파티션 읽기 요청에 응답하고 디스크에 수록된 메시지를 전송한다.

### 클러스터 (Cluster)
- 카프카도 여러 대의 서버(Broker) 를 묶어서 하나의 거대한 서비스(Cluster) 처럼 움직이기 때문에,
- 특정 서버에 장애가 발생하더라도 카프카를 이용하는 클라이언트에게는 정상적인 처리와 응답을 제공할 수 있다.
- 또한 클러스터 내에 카프카 서버를 추가할 때마다 그만큼 메시지의 수신과 전달에 대한 처리량이 증가하기 때문에 확장성 측면에서도 장점이 있다.

### 토픽과 파티션(Topic, Partition)
> 카프카의 메시지는 토픽(Topic) 단위로 분류된다.
> 하나의 토픽은 여러 개의 파티션(Partition) 으로 구성될 수 있다.

![토픽이미지](https://miro.medium.com/v2/resize:fit:1100/format:webp/1*GSF_9QXGe6Jd6nZJ69Ed1Q.png)

- 메시지는 파티션에 추가되는 형태로만 기록되며, 맨 앞부터 제일 끝까지의 순서로 읽힌다. 
- 대개 하나의 토픽은 여러 개의 파티션을 갖지만, 메시지의 처리 순서는 토픽이 아닌 파티션별로 관리된다. 
- Kafka 클러스터를 적용하면 각 파티션은 서로 다른 서버에 분산될 수 있는데, 이러한 특징 때문에 하나의 토픽이 여러 서버에 걸쳐 수평적으로 확장될 수 있다. 
- 이는 단일 서버로 처리할 때보다 훨씬 높은 성능을 가질 수 있게 해준다.

### 메시지 (Message)
> `데이터의 기본 단위`

- 카프카는 메시지를 바이트 배열의 데이터로 간주하므로 특정 형식이나 의미를 갖지는 않는다. 
- 이 때문에 카프카에는 어떠한 데이터 형태이든지 저장이 가능하고, 메시지를 읽어들인 후에는 적절한 형태로 변환하여 사용해야 한다.
- 카프카의 메시지는 토픽 내의 파티션에 기록되는데, 이 때 특정 메시지를 기록할 파티션을 결정하기 위해 메시지에 담긴 키 값을 해시 처리하고, 그 값과 일치하는 파티션에 메시지를 기록하게 된다. 

### 파티셔너(Partitioner)
> `메시지의 키 값을 해시 처리하는 로직을 파티셔너(Partitioner)` 
- 파티셔너를 이용해 `동일한 키 값을 가지는 여러 개의 메시지는 항상 동일한 파티션에 기록`되게 된다. 
- 만약 `메시지의 키 값이 null`이면 카프카 내부의 기본 파티셔너는 각 파티션에 저장되는 `메시지 개수의 균형을 맞추기 위해 라운드 로빈(Round-Robin) 방식`으로 메시지를 기록한다.

## 2. 카프카 클라이언트
### 프로듀서(Producer)
- 프로듀서는 새로운 메시지를 특정 토픽에 생성하는데, 이 때 프로듀서는 기본적으로 메시지가 어떤 파티션에 기록하는지는 관여하지 않는다. 
- 만약 프로듀서가 특정한 메시지를 특정한 파티션에 기록하고 싶을 때에는 메시지 키와 파티셔너를 활용할 수 있다. 
- 파티셔너는 키의 해시 값을 생성하고 그것을 특정 파티션에 대응시키는데, 이러한 방식으로 지정된 키를 갖는 메시지가 항상 같은 파티션에 기록되게 해준다.

### 컨슈머(Consumer)
- 컨슈머는 하나 이상의 토픽을 구독하면서 메시지가 생성된 순서로 읽는다. 
- 컨슈머는 메시지를 읽을 때마다 파티션 단위로 오프셋을 유지하여 읽는 메시지의 위치를 알 수 있다. 
- 각각의 파티션마다 오프셋이 있기 때문에 컨슈머가 읽기를 중단했다가 다시 시작하더라도 언제든 그 다음 메시지부터 읽을 수 있게 된다.

#### Commit Offset
> 컨슈머로부터 ‘여기까지의 오프셋은 처리했다’ 는 것을 확인하는 오프셋
#### Current Offset  
> 컨슈머가 어디까지 메시지를 읽었는지를 나타내는 오프셋

### 컨슈머 그룹 (Consumer Group)
- 카프카 컨슈머들은 컨슈머 그룹(Consumer Group) 에 속하게 된다. 
- 여러 개의 컨슈머가 같은 컨슈머 그룹에 속할 때에는 각 컨슈머가 해당 토픽의 다른 파티션을 분담해서 메시지를 읽을 수 있다. 
  - 하나의 컨슈머 그룹에 더 많은 컨슈머를 추가하면 카프카 토픽의 데이터 소비를 확장할 수 있다. 
  - 즉 `더 많은 컨슈머를 추가하는 것이 메시지 소비 성능 확장`이 중요한 방법이 된다.
- 주의할 점은, `한 토픽의 각 파티션은 (마치 함수처럼) 하나의 컨슈머만 처리`할 수 있다는 것이다. 
- `하나의 토픽 내의 파티션 개수보다 더 많은 수의 컨슈머를 추가하는 것은 의미가 없다`는 것을 명심해야 한다.

### 리밸런싱(Rebalancing)
> 한 컨슈머로부터 다른 컨슈머로 파티션 소유권이 이전되는 것

- 컨슈머 그룹의 가용성과 확장성을 높여주기 때문에 중요하다
- 리밸런싱동안 컨슈머들은 메시지를 읽을 수 없는 상태에 빠지므로(stop the world) 부적절한 리밸런싱을 피하는 것이 중요하다.

#### 리밸런싱 발생 상황
- 컨슈머 그룹 내에 새로운 컨슈머가 추가
- 특정 컨슈머에 문제가 생겨 중단
- 해당 컨슈머 그룹이 바라보는 토픽 내에 새로운 파티션 추가

## 3. 스프링 카프카 yml 설정
application.yml
```
spring:
  kafka:
    consumer:
      bootstrap-servers: localhost:9094
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.JsonSerializer
    producer:
      bootstrap-servers: localhost:9092
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.JsonSerializer
    listener:
      ack-mode: manual
      concurrency: 2
```
- spring.kafka.consumer/producer
  - bootstrap-servers : Kafka 연결에 사용될 호스트:포트
  - auto-offset-reset : Kafka 초기 offset이 없거나, 더이상 offset이 없을때 수행
    - latest : 가장 최근에 생산된 메시지 offset reset
    - earliest : 가장 오래된 메시지로 offset reset
    - none : offset 정보없을때, Exception 발생
    - key-deserializer / value-deserializer : Kafka에서 데이터를 수신할 때, key / value 역직렬화
- spring.kafka.listener
  - ack-mode
    - manual : 개발자가 직접 Acknowledgment.acknowledge()를 호출하여 오프셋을 커밋
    - manual_immediate : 즉시 오프셋을 커밋
  - concurrency : 최대 N개의 Consumer가 동시에 메시지를 처리
